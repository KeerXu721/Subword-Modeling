{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_tsv_data(filepath):\n",
    "    \"\"\"\n",
    "    Reads a TSV file and returns a list of (root_form, inflectional_info, inflected_form) tuples.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file, delimiter=\"\\t\")  # TSV format\n",
    "        for row in reader:\n",
    "            if len(row) == 3:  # Ensure correct format\n",
    "                root, inflected, info = row\n",
    "                data.append((root, info, inflected))  # Maintain (root, info, inflected) order\n",
    "    return data\n",
    "\n",
    "def load_test_data(filepath):\n",
    "    \"\"\"\n",
    "    Reads a TSV file and returns a list of (root_form, inflected_form) tuples.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "        reader = csv.reader(file, delimiter=\"\\t\")  # TSV format\n",
    "        for row in reader:\n",
    "            if len(row) == 2:  # Ensure correct format\n",
    "                root, info = row\n",
    "                data.append((root, info))  # Maintain (root, inflected) order\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import torch\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.char2idx = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2}  # Special tokens\n",
    "        self.idx2char = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\"}\n",
    "        self.feature2idx = {}  # Inflectional features\n",
    "        self.idx2feature = {}\n",
    "\n",
    "    def add_word(self, word):\n",
    "        for char in word:\n",
    "            if char not in self.char2idx:\n",
    "                idx = len(self.char2idx)\n",
    "                self.char2idx[char] = idx\n",
    "                self.idx2char[idx] = char\n",
    "\n",
    "    def add_feature(self, feature):\n",
    "        features = feature.split(\";\")\n",
    "        for feat in features:\n",
    "            if feat not in self.feature2idx:\n",
    "                idx = len(self.feature2idx)\n",
    "                self.feature2idx[feat] = idx\n",
    "                self.idx2feature[idx] = feat\n",
    "        # if feature not in self.feature2idx:  \n",
    "        #     idx = len(self.feature2idx)\n",
    "        #     self.feature2idx[feature] = idx\n",
    "        #     self.idx2feature[idx] = feature\n",
    "\n",
    "    def encode_word(self, word):\n",
    "        return [self.char2idx[char] for char in word] + [self.char2idx[\"<EOS>\"]]\n",
    "\n",
    "    def encode_feature(self, feature):\n",
    "        features = feature.split(\";\")\n",
    "        return [self.feature2idx[feat] if feat in self.feature2idx else 0 for feat in features]\n",
    "        # return self.feature2idx[feature] if feature in self.feature2idx else 0  # Default to 0 if unknown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class InflectionDataset(Dataset):\n",
    "    def __init__(self, filepath, vocab):\n",
    "        \"\"\"\n",
    "        filepath: Path to the TSV file\n",
    "        vocab: Instance of Vocabulary class\n",
    "        \"\"\"\n",
    "        self.data = load_tsv_data(filepath)  # list of (root_form, inflectional_info, inflected_form) tuples\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        root_form, inflectional_info, inflected_form = self.data[idx]\n",
    "        \n",
    "        root_encoded = self.vocab.encode_word(root_form)\n",
    "        inflected_encoded = [self.vocab.char2idx[\"<SOS>\"]] + self.vocab.encode_word(inflected_form)\n",
    "        feature_encoded = self.vocab.encode_feature(inflectional_info)\n",
    "\n",
    "        return torch.tensor(root_encoded), torch.tensor(feature_encoded), torch.tensor(inflected_encoded)\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, filepath, vocab):\n",
    "        \"\"\"\n",
    "        root_data: List of root sequences.\n",
    "        feature_data: List of features (inflectional information) corresponding to the roots.\n",
    "        \"\"\"\n",
    "        self.data = load_test_data(filepath)  # list of (root_form, inflectional_info, inflected_form) tuples\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        root_form, inflectional_info = self.data[idx]\n",
    "        \n",
    "        root_encoded = self.vocab.encode_word(root_form)\n",
    "        feature_encoded = self.vocab.encode_feature(inflectional_info)\n",
    "\n",
    "        return torch.tensor(root_encoded), torch.tensor(feature_encoded)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: List of (root_encoded, feature_encoded, inflected_encoded) tuples\n",
    "    Returns: Padded tensors for root forms, features, and inflected forms\n",
    "    \"\"\"\n",
    "    roots, features, inflecteds = zip(*batch)\n",
    "\n",
    "    # Pad sequences to the longest in the batch\n",
    "    roots_padded = pad_sequence(roots, batch_first=True, padding_value=0)  \n",
    "    inflecteds_padded = pad_sequence(inflecteds, batch_first=True, padding_value=0)\n",
    "    # features = torch.tensor(features)  # Already numerical, no need for padding\n",
    "    features = pad_sequence(features, batch_first=True, padding_value=0)\n",
    "\n",
    "    return roots_padded, features, inflecteds_padded\n",
    "\n",
    "def test_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: List of (root_encoded, feature_encoded) tuples\n",
    "    Returns: Padded tensors for root forms and features\n",
    "    \"\"\"\n",
    "    roots, features = zip(*batch)\n",
    "\n",
    "    # Pad sequences to the longest in the batch\n",
    "    roots_padded = pad_sequence(roots, batch_first=True, padding_value=0)  \n",
    "    # features = torch.tensor(features)  # Already numerical, no need for padding\n",
    "    features = pad_sequence(features, batch_first=True, padding_value=0)\n",
    "\n",
    "    return roots_padded, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def prepare_data(language):\n",
    "    train_data = 'dataset/' + language + '.train.tsv'\n",
    "    dev_data = 'dataset/' + language + '.dev.tsv'\n",
    "    test_data = 'dataset/' + language + '.test.tsv'\n",
    "    data = load_tsv_data(train_data)\n",
    "\n",
    "    vocab = Vocabulary()\n",
    "    for root, feat, inflected in data:\n",
    "        vocab.add_word(root)\n",
    "        vocab.add_word(inflected)\n",
    "        vocab.add_feature(feat)\n",
    "    \n",
    "    return vocab, train_data, dev_data, test_data\n",
    "\n",
    "def prepare_dataset(language, batch=16):\n",
    "    vocab, train_data, dev_data, test_data = prepare_data(language)\n",
    "    train_dataset = InflectionDataset(train_data, vocab)\n",
    "    dev_dataset = InflectionDataset(dev_data, vocab)\n",
    "    test_dataset = TestDataset(test_data, vocab)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch, shuffle=True, collate_fn=collate_fn)\n",
    "    dev_dataloader = DataLoader(dev_dataset, batch_size=batch, shuffle=False, collate_fn=collate_fn)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch, shuffle=False, collate_fn=test_collate_fn)\n",
    "\n",
    "    return vocab, train_dataloader, dev_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, feature_dim, padding_idx = 0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=padding_idx)\n",
    "        self.feature_embedding = nn.Embedding(feature_dim, emb_dim, padding_idx=padding_idx)\n",
    "\n",
    "        self.lstm = nn.LSTM(emb_dim * 2, hidden_dim, batch_first=True)  # Concatenate both embeddings\n",
    "\n",
    "        # self.lstm = nn.LSTM(emb_dim + hidden_dim, hidden_dim, batch_first=True)  # LSTM input size doubled\n",
    "\n",
    "        # self.feature_proj = nn.Linear(emb_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, root_seq, feature):\n",
    "        \"\"\"\n",
    "        root_seq: (batch_size, root_seq_len)\n",
    "        feature: (batch_size, feature_seq_len)\n",
    "        \"\"\"\n",
    "        root_embedded = self.embedding(root_seq)\n",
    "        feature_embedded = self.feature_embedding(feature)\n",
    "        # print(root_seq.size(), feature.size())\n",
    "        # print(root_embedded.size(), feature_embedded.size())\n",
    "        combined_input = torch.cat((root_embedded, feature_embedded), dim=1)\n",
    "        lstm_out, hidden = self.lstm(combined_input)  # Pass through LSTM\n",
    "        return lstm_out, hidden\n",
    "        # root_embedded = self.embedding(root_seq)\n",
    "        # feature_embedded = self.feature_proj(self.feature_embedding(feature))  # Ensure hidden_dim match\n",
    "\n",
    "        # # feature_embedded = self.feature_embedding(feature).unsqueeze(1) \n",
    "        # feature_expanded = feature_embedded.unsqueeze(1)  # (batch_size, 1, hidden_dim)\n",
    "        # feature_expanded = feature_expanded.expand(-1, root_embedded.size(1), -1)  # (batch_size, seq_len, emb_dim)\n",
    "        # lstm_input = torch.cat((root_embedded, feature_expanded), dim=-1)\n",
    "\n",
    "        # # lstm_out, hidden = self.lstm(lstm_input)  # Pass through LSTM\n",
    "        # h_0 = feature_embedded.unsqueeze(0)  # (num_layers, batch_size, hidden_dim)\n",
    "        # c_0 = torch.zeros_like(h_0)  # Initialize cell state to zeros\n",
    "\n",
    "        # lstm_out, hidden = self.lstm(lstm_input, (h_0, c_0))  # Pass through LSTM\n",
    "    \n",
    "        # return lstm_out, hidden  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim, hidden_dim)  # Project encoder outputs\n",
    "        self.hidden_proj = nn.Linear(hidden_dim, hidden_dim)  # Project decoder hidden state\n",
    "        self.energy = nn.Linear(hidden_dim, 1, bias=False)  # Energy computation\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        hidden: (num_layers, batch_size, hidden_dim)\n",
    "        encoder_outputs: (batch_size, seq_len, hidden_dim)\n",
    "        \"\"\"\n",
    "        hidden = self.hidden_proj(hidden[-1]).squeeze(0).unsqueeze(1)  # Ensure (batch_size, 1, hidden_dim)\n",
    "\n",
    "        attn_applied = self.attn(encoder_outputs)  # Transform encoder outputs\n",
    "\n",
    "        scores = self.energy(torch.tanh(attn_applied + hidden))  # Compute alignment scores\n",
    "\n",
    "        attn_weights = torch.softmax(scores.squeeze(2), dim=1)  # (batch_size, seq_len)\n",
    "\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs)  # (batch_size, 1, hidden_dim)\n",
    "\n",
    "        return context.squeeze(1), attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, sos_token, eos_token, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.sos_token = sos_token\n",
    "        self.eos_token = eos_token\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.lstm = nn.LSTM(emb_dim + hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.attention = Attention(hidden_dim)\n",
    "\n",
    "    def forward(self, input_char, hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        input_char: (batch_size,)\n",
    "        hidden: (num_layers, batch_size, hidden_dim)\n",
    "        encoder_outputs: (batch_size, seq_len, hidden_dim)\n",
    "        \"\"\"\n",
    "\n",
    "        embedded = self.embedding(input_char).unsqueeze(1)  # (batch_size, 1, emb_dim)\n",
    "\n",
    "        # Compute attention\n",
    "        context, attn_weights = self.attention(hidden, encoder_outputs)  # (batch_size, hidden_dim)\n",
    "\n",
    "        # Concatenate context with input\n",
    "        lstm_input = torch.cat((embedded, context.unsqueeze(1)), dim=2)  # (batch_size, 1, emb_dim + hidden_dim)\n",
    "        output, hidden = self.lstm(lstm_input, hidden)\n",
    "\n",
    "        # Final output\n",
    "        output = self.fc_out(torch.cat((output.squeeze(1), context), dim=1))  # (batch_size, output_dim)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def predict(self, encoder_outputs, hidden, max_len=20):\n",
    "        \"\"\" Decoder step during inference without teacher forcing \"\"\"\n",
    "        input_char = torch.tensor([self.sos_token]).to(self.device)  # Starting with <SOS> token\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for _ in range(max_len):\n",
    "            # Get the embedding of the input token\n",
    "            embedded = self.embedding(input_char).unsqueeze(0)  # (1, 1, emb_dim)\n",
    "            \n",
    "            # Compute the context vector from the attention mechanism\n",
    "            context, attn_weights = self.attention(hidden[0], encoder_outputs)  # (batch_size, hidden_dim)\n",
    "            \n",
    "            # Concatenate the context with the embedded input\n",
    "            lstm_input = torch.cat((embedded, context.unsqueeze(1)), dim=2)  # (1, 1, emb_dim + hidden_dim)\n",
    "            \n",
    "            # Perform the LSTM forward pass\n",
    "            output, hidden = self.lstm(lstm_input, hidden)\n",
    "            \n",
    "            # Predict the next token from the output\n",
    "            output = self.fc_out(output.squeeze(1))  # (batch_size, vocab_size)\n",
    "            pred_token = output.argmax(dim=1).item()  # Get the predicted token (most likely one)\n",
    "            \n",
    "            # Append the predicted token to the predictions list\n",
    "            predictions.append(pred_token)\n",
    "            \n",
    "            # If the EOS token is predicted, stop the generation\n",
    "            if pred_token == self.eos_token:\n",
    "                break\n",
    "            \n",
    "            # The predicted token becomes the input for the next timestep\n",
    "            input_char = torch.tensor([pred_token]).to(self.device)\n",
    "        \n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, sos_token, eos_token, max_len=20):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.sos_token = sos_token\n",
    "        self.eos_token = eos_token\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def forward(self, root_seq, feature, target_seq, teacher_forcing_ratio=0.5):\n",
    "        \"\"\" Training mode (uses teacher forcing) \"\"\"\n",
    "        encoder_outputs, hidden = self.encoder(root_seq, feature)\n",
    "        outputs = []\n",
    "\n",
    "        input_char = target_seq[:, 0]  # First input is the <SOS> token\n",
    "        for t in range(1, target_seq.shape[1]):\n",
    "            output, hidden = self.decoder(input_char, hidden, encoder_outputs)\n",
    "            outputs.append(output.unsqueeze(1))\n",
    "\n",
    "            # Decide whether to use teacher forcing\n",
    "            use_teacher_forcing = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            input_char = target_seq[:, t] if use_teacher_forcing else output.argmax(1)\n",
    "\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "    def predict(self, root_seq, feature, max_len=None):\n",
    "        \"\"\" Inference mode (no teacher forcing) \"\"\"\n",
    "        self.eval()  # Set the model to evaluation mode\n",
    "        encoder_outputs, hidden = self.encoder(root_seq, feature)\n",
    "        \n",
    "        # Initialize the input to the decoder with the <SOS> token\n",
    "        input_char = torch.full((root_seq.size(0), 1), self.sos_token, dtype=torch.long).to(self.device)\n",
    "        predicted_sequence = []\n",
    "\n",
    "        # Use the decoder to predict the next token step-by-step\n",
    "        for t in range(self.max_len):\n",
    "            output, hidden = self.decoder.predict(input_char, hidden, encoder_outputs)\n",
    "            \n",
    "            # Get the predicted token (argmax gives the most likely token)\n",
    "            predicted_token = output.argmax(2)  # Assuming output is (batch_size, 1, vocab_size)\n",
    "            predicted_sequence.append(predicted_token)\n",
    "\n",
    "            # Stop predicting if the <EOS> token is reached\n",
    "            if predicted_token.item() == self.eos_token:\n",
    "                break\n",
    "\n",
    "            # Update input for the next time step (use predicted token)\n",
    "            input_char = predicted_token\n",
    "\n",
    "        # Concatenate the predicted tokens\n",
    "        predicted_sequence = torch.cat(predicted_sequence, dim=1)\n",
    "        return predicted_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def train_model(dataloader, model, optimizer, criterion, valid_loader, num_epochs=20, save_path=\"best_model.pth\"):\n",
    "    model.train()  # Ensure the model is in training mode\n",
    "    best_val_loss = float('inf')  # Initialize the best validation loss to a large number\n",
    "    patience_counter = 0  # To implement early stopping (optional)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        for root_seq, feature, target_seq in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(root_seq, feature, target_seq)\n",
    "            loss = criterion(output.view(-1, output.shape[-1]), target_seq[:, 1:].contiguous().view(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        val_loss = validate(model, valid_loader, criterion)\n",
    "        print(f\"Epoch {epoch+1}, Training Loss: {loss.item():.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        # Save the model if validation loss improves\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0  # Reset patience counter if validation improves\n",
    "            torch.save(model.state_dict(), save_path)  # Save the model at the best validation step\n",
    "            print(f\"Model saved at epoch {epoch+1}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Early stopping (optional)\n",
    "        if patience_counter >= 5:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# Helper validation function\n",
    "def validate(model, valid_loader, criterion):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # No gradients needed for validation\n",
    "        for root_seq, feature, target_seq in valid_loader:\n",
    "            output = model(root_seq, feature, target_seq)\n",
    "            loss = criterion(output.view(-1, output.shape[-1]), target_seq[:, 1:].contiguous().view(-1))\n",
    "            total_loss += loss.item()\n",
    "    avg_val_loss = total_loss / len(valid_loader)\n",
    "    model.train()  # Return the model to training mode after validation\n",
    "    return avg_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save(seq2seq_model, dataloader, vocab, output_file, max_len=10):\n",
    "    \"\"\"\n",
    "    Generates the predicted inflected forms for data in the dataloader and saves to a file.\n",
    "    \n",
    "    Parameters:\n",
    "    - seq2seq_model: The trained Seq2Seq model.\n",
    "    - dataloader: DataLoader containing test data with root sequences and features.\n",
    "    - vocab: Vocabulary mapping for converting token indices to characters.\n",
    "    - max_len: Maximum length of the generated sequence.\n",
    "    - output_file: File path to save the predicted inflected forms.\n",
    "    \"\"\"\n",
    "    seq2seq_model.eval()\n",
    "    device = seq2seq_model.device\n",
    "    \n",
    "    with open(output_file, \"w\") as f:\n",
    "        for root_seq, feature in dataloader:\n",
    "            root_seq, feature = root_seq.to(device), feature.to(device)\n",
    "            batch_size = root_seq.shape[0]\n",
    "            \n",
    "            # Encode the input\n",
    "            with torch.no_grad():\n",
    "                encoder_outputs, hidden = seq2seq_model.encoder(root_seq, feature)\n",
    "            \n",
    "            # Initialize decoder input with <SOS> token\n",
    "            input_char = torch.full((batch_size,), seq2seq_model.sos_token, dtype=torch.long, device=device)\n",
    "            \n",
    "            predicted_seq = [[] for _ in range(batch_size)]\n",
    "            \n",
    "            for t in range(max_len):\n",
    "                with torch.no_grad():\n",
    "                    output, hidden = seq2seq_model.decoder(input_char, hidden, encoder_outputs)\n",
    "                \n",
    "                predicted_char = output.argmax(1)  # Get the most likely character index\n",
    "                \n",
    "                for i in range(batch_size):\n",
    "                    if predicted_char[i].item() == seq2seq_model.eos_token:\n",
    "                        continue  # Stop predicting for this sequence if <EOS> is reached\n",
    "                    predicted_seq[i].append(predicted_char[i].item())\n",
    "                \n",
    "                input_char = predicted_char  # Next input is the predicted character\n",
    "            \n",
    "            # Convert predicted indices to characters and save to file\n",
    "            for seq in predicted_seq:\n",
    "                predicted_form = ''.join([vocab.idx2char[idx] for idx in seq])\n",
    "                f.write(predicted_form + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 2.1590, Validation Loss: 2.1171\n",
      "Model saved at epoch 1\n",
      "Epoch 2, Training Loss: 1.2239, Validation Loss: 1.4436\n",
      "Model saved at epoch 2\n",
      "Epoch 3, Training Loss: 0.8431, Validation Loss: 0.8481\n",
      "Model saved at epoch 3\n",
      "Epoch 4, Training Loss: 0.3240, Validation Loss: 0.6240\n",
      "Model saved at epoch 4\n",
      "Epoch 5, Training Loss: 0.1805, Validation Loss: 0.5514\n",
      "Model saved at epoch 5\n",
      "Epoch 6, Training Loss: 0.2519, Validation Loss: 0.4855\n",
      "Model saved at epoch 6\n",
      "Epoch 7, Training Loss: 0.1717, Validation Loss: 0.4704\n",
      "Model saved at epoch 7\n",
      "Epoch 8, Training Loss: 0.1322, Validation Loss: 0.4242\n",
      "Model saved at epoch 8\n",
      "Epoch 9, Training Loss: 0.0776, Validation Loss: 0.3752\n",
      "Model saved at epoch 9\n",
      "Epoch 10, Training Loss: 0.0950, Validation Loss: 0.3722\n",
      "Model saved at epoch 10\n",
      "Epoch 11, Training Loss: 0.0661, Validation Loss: 0.4193\n",
      "Epoch 12, Training Loss: 0.0742, Validation Loss: 0.3745\n",
      "Epoch 13, Training Loss: 0.0993, Validation Loss: 0.3974\n",
      "Epoch 14, Training Loss: 0.1955, Validation Loss: 0.3754\n",
      "Epoch 15, Training Loss: 0.1759, Validation Loss: 0.3206\n",
      "Model saved at epoch 15\n",
      "Epoch 16, Training Loss: 0.0519, Validation Loss: 0.3093\n",
      "Model saved at epoch 16\n",
      "Epoch 17, Training Loss: 0.0846, Validation Loss: 0.4329\n",
      "Epoch 18, Training Loss: 0.0829, Validation Loss: 0.4554\n",
      "Epoch 19, Training Loss: 0.0879, Validation Loss: 0.3735\n",
      "Epoch 20, Training Loss: 0.0589, Validation Loss: 0.4754\n",
      "Epoch 1, Training Loss: 2.4501, Validation Loss: 2.4085\n",
      "Model saved at epoch 1\n",
      "Epoch 2, Training Loss: 1.8749, Validation Loss: 1.9858\n",
      "Model saved at epoch 2\n",
      "Epoch 3, Training Loss: 1.0806, Validation Loss: 1.5458\n",
      "Model saved at epoch 3\n",
      "Epoch 4, Training Loss: 0.8437, Validation Loss: 1.1067\n",
      "Model saved at epoch 4\n",
      "Epoch 5, Training Loss: 0.3914, Validation Loss: 0.7915\n",
      "Model saved at epoch 5\n",
      "Epoch 6, Training Loss: 0.2530, Validation Loss: 0.5181\n",
      "Model saved at epoch 6\n",
      "Epoch 7, Training Loss: 0.0845, Validation Loss: 0.5344\n",
      "Epoch 8, Training Loss: 0.0549, Validation Loss: 0.5378\n",
      "Epoch 9, Training Loss: 0.0379, Validation Loss: 0.3552\n",
      "Model saved at epoch 9\n",
      "Epoch 10, Training Loss: 0.0380, Validation Loss: 0.5317\n",
      "Epoch 11, Training Loss: 0.0174, Validation Loss: 0.3732\n",
      "Epoch 12, Training Loss: 0.0130, Validation Loss: 0.5447\n",
      "Epoch 13, Training Loss: 0.0186, Validation Loss: 0.4605\n",
      "Epoch 14, Training Loss: 0.0115, Validation Loss: 0.3950\n",
      "Early stopping triggered.\n",
      "Epoch 1, Training Loss: 2.0711, Validation Loss: 2.3712\n",
      "Model saved at epoch 1\n",
      "Epoch 2, Training Loss: 1.4314, Validation Loss: 1.9991\n",
      "Model saved at epoch 2\n",
      "Epoch 3, Training Loss: 0.8672, Validation Loss: 1.6654\n",
      "Model saved at epoch 3\n",
      "Epoch 4, Training Loss: 0.4451, Validation Loss: 1.4172\n",
      "Model saved at epoch 4\n",
      "Epoch 5, Training Loss: 0.3439, Validation Loss: 1.3473\n",
      "Model saved at epoch 5\n",
      "Epoch 6, Training Loss: 0.1462, Validation Loss: 1.3208\n",
      "Model saved at epoch 6\n",
      "Epoch 7, Training Loss: 0.0811, Validation Loss: 1.3366\n",
      "Epoch 8, Training Loss: 0.0997, Validation Loss: 1.3599\n",
      "Epoch 9, Training Loss: 0.0529, Validation Loss: 1.3958\n",
      "Epoch 10, Training Loss: 0.0775, Validation Loss: 1.4622\n",
      "Epoch 11, Training Loss: 0.0558, Validation Loss: 1.4454\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "languages = ['xty', 'kbd', 'swc']\n",
    "\n",
    "for language in languages:\n",
    "    vocab, train_dataloader, dev_dataloader, test_dataloader = prepare_dataset(language, batch=128)\n",
    "\n",
    "    # Initialize model, optimizer, and loss function\n",
    "    encoder = Encoder(input_dim=len(vocab.char2idx), emb_dim=256, hidden_dim=256, feature_dim=len(vocab.feature2idx))\n",
    "    decoder = Decoder(output_dim=len(vocab.char2idx), emb_dim=256, hidden_dim=256, sos_token=vocab.char2idx[\"<SOS>\"], eos_token=vocab.char2idx[\"<EOS>\"])\n",
    "    model = Seq2Seq(encoder, decoder, device=\"cpu\", sos_token=vocab.char2idx[\"<SOS>\"], eos_token=vocab.char2idx[\"<EOS>\"])\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "    train_model(train_dataloader, model, optimizer, criterion, dev_dataloader)\n",
    "\n",
    "    # Load the best model and predict on the test set\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\", map_location=\"cpu\"))\n",
    "    predict_and_save(model, test_dataloader, vocab, output_file=language+'.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
