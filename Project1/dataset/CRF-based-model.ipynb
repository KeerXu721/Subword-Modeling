{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from TorchCRF import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(filepath):\n",
    "    # given the source file path, return all input words\n",
    "    words = []\n",
    "    with open(filepath, encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            words += [line.strip()]\n",
    "    return words\n",
    "\n",
    "def tag_original_word(original_word, tokenized_word):\n",
    "    # Initialize pointers for the original word and tags\n",
    "    org_idx = tok_idx = 0\n",
    "    tags = []\n",
    "    tag = \"B\"\n",
    "    # Iterate through the tokenized word\n",
    "    while tok_idx < len(tokenized_word) and org_idx < len(original_word):\n",
    "        # Skip characters not in the original word\n",
    "        if tokenized_word[tok_idx] == original_word[org_idx]:\n",
    "            tags.append(tag)\n",
    "            if tag == \"B\":\n",
    "                tag = \"I\"\n",
    "            org_idx += 1\n",
    "        elif tokenized_word[tok_idx] == \" \":\n",
    "            tag = \"B\"\n",
    "            tok_idx += 1\n",
    "        else:\n",
    "            tok_idx += 1\n",
    "\n",
    "    # Return the final tags as a string\n",
    "    return \"\".join(tags)\n",
    "\n",
    "# preparing labels for the dataset\n",
    "# Using \"B\", \"I\" labeling, B for beginning of the word, I for inside the word\n",
    "def get_labels(origional_words, tokenized_words):\n",
    "    labels = []\n",
    "    for o, t in zip(origional_words, tokenized_words):\n",
    "        labels.append(tag_original_word(o, t))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(word, char_to_idx, is_input):\n",
    "    if is_input:\n",
    "        return [char_to_idx[ch] if ch in char_to_idx else char_to_idx['<unk>'] for ch in word]\n",
    "    return [char_to_idx['<start>']] + [char_to_idx[ch] for ch in word] + [char_to_idx['<end>']]\n",
    "\n",
    "def decode(encoded_word, idx_to_char):\n",
    "    return ''.join(idx_to_char[idx] for idx in encoded_word if idx_to_char[idx] not in ['<pad>', '<unk>', '<start>', '<end>'])\n",
    "\n",
    "def encode_whole(words, char_to_idx, is_input):\n",
    "    words_encoded = []\n",
    "    for word in words:\n",
    "        encoded_word = encode(word, char_to_idx, is_input)\n",
    "        words_encoded.append(encoded_word)\n",
    "    \n",
    "    return words_encoded\n",
    "\n",
    "def decode_whole(encoded_words, idx_to_char):   \n",
    "    decoded_words = []\n",
    "    for encoded_word in encoded_words:\n",
    "        decoded_word = decode(encoded_word, idx_to_char)\n",
    "        decoded_words.append(decoded_word)\n",
    "    \n",
    "    return decoded_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# labels = get_labels('dataset/shp.train.tgt')\n",
    "input_words = get_words('dataset/shp.train.src')\n",
    "output_words = get_words('dataset/shp.train.tgt')\n",
    "\n",
    "train_labels = get_labels(input_words, output_words)\n",
    "# print(train_labels)\n",
    "# print(Counter(''.join(train_labels)))\n",
    "\n",
    "val_input_words = get_words('dataset/shp.dev.src')\n",
    "val_output_words = get_words('dataset/shp.dev.tgt')\n",
    "\n",
    "val_labels = get_labels(val_input_words, val_output_words)\n",
    "\n",
    "test_words = get_words('dataset/shp.test.src')\n",
    "\n",
    "# get char to index mapping and index to char mapping\n",
    "all_chars = set(char for seq in input_words + val_input_words for char in seq)\n",
    "all_labels = set(label for lbls in train_labels for label in lbls)\n",
    "\n",
    "char_to_idx = {char: idx + 1 for idx, char in enumerate(sorted(all_chars))}  # Reserve 0 for padding\n",
    "char_to_idx[\"<UNK>\"] = len(char_to_idx) + 1 \n",
    "label_to_idx = {label: idx for idx, label in enumerate(sorted(all_labels))}\n",
    "idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "# encoded_origin = encode_whole(input_words, char_to_idx, is_input=True)\n",
    "# encoded_tokenized = encode_whole(train_labels, label_to_idx, is_input=False)\n",
    "# encoded_val = encode_whole(val_input_words, char_to_idx, is_input=True)\n",
    "# encoded_val_tokenized = encode_whole(val_labels, label_to_idx, is_input=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceLabelingDataset(Dataset):\n",
    "    def __init__(self, sequences, labels, char_to_idx, label_to_idx):\n",
    "        self.sequences = [[char_to_idx.get(char, char_to_idx['<UNK>']) for char in seq] for seq in sequences]\n",
    "        self.labels = [[label_to_idx.get(label) for label in seq] for seq in labels]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "        return torch.tensor(sequence, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    sequences, labels = zip(*batch)\n",
    "    max_len = max(max(len(seq) for seq in sequences), max(len(lbl) for lbl in labels))\n",
    "    \n",
    "    # Pad sequences\n",
    "    padded_sequences = [\n",
    "        torch.cat([seq, torch.zeros(max_len - len(seq), dtype=torch.long)], dim=0)\n",
    "        for seq in sequences\n",
    "    ]\n",
    "    \n",
    "    # Pad labels\n",
    "    padded_labels = [\n",
    "        torch.cat([lbl, torch.full((max_len - len(lbl),), -1, dtype=torch.long)], dim=0)\n",
    "        for lbl in labels\n",
    "    ]\n",
    "\n",
    "    # Create a mask to indicate valid positions (1 for valid, 0 for padding)\n",
    "    mask = [\n",
    "        torch.cat([torch.ones(len(seq), dtype=torch.uint8), torch.zeros(max_len - len(seq), dtype=torch.uint8)], dim=0)\n",
    "        for seq in sequences\n",
    "    ]\n",
    "    \n",
    "    # Ensure the first timestep of the mask is always 1\n",
    "    for m in mask:\n",
    "        m[0] = 1\n",
    "    \n",
    "    return torch.stack(padded_sequences), torch.stack(padded_labels), torch.stack(mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = SequenceLabelingDataset(input_words, train_labels, char_to_idx, label_to_idx)\n",
    "val_dataset = SequenceLabelingDataset(val_input_words, val_labels, char_to_idx, label_to_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM-CRF Model\n",
    "class BiLSTMCRF(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, tagset_size):\n",
    "        super(BiLSTMCRF, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, num_layers=1, bidirectional=True, batch_first=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.crf = CRF(tagset_size, batch_first=True)\n",
    "\n",
    "    def forward(self, x, tags=None, mask=None):\n",
    "        embeddings = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(embeddings)\n",
    "        emissions = self.hidden2tag(lstm_out)\n",
    "        \n",
    "        if tags is not None:\n",
    "            valid_mask = mask.bool()\n",
    "            loss = -self.crf(emissions, tags, mask=valid_mask, reduction='mean')\n",
    "            return loss\n",
    "        else:\n",
    "            return self.crf.decode(emissions, mask=mask.bool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 28/28 [00:01<00:00, 20.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.6133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 28/28 [00:01<00:00, 16.81batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 1.6568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 28/28 [00:02<00:00, 12.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Loss: 1.4229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 28/28 [00:03<00:00,  9.28batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 1.2546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 28/28 [00:03<00:00,  7.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Loss: 1.0682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 28/28 [00:02<00:00, 12.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Loss: 0.9981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 28/28 [00:02<00:00, 11.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Loss: 0.8342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 28/28 [00:02<00:00, 10.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Loss: 0.7512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 28/28 [00:02<00:00, 12.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Loss: 0.7032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 28/28 [00:02<00:00, 13.33batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 0.5948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "vocab_size = len(char_to_idx) + 1\n",
    "tagset_size = len(label_to_idx)\n",
    "embedding_dim = 50\n",
    "hidden_dim = 100\n",
    "\n",
    "# Instantiate Model\n",
    "model = BiLSTMCRF(vocab_size, embedding_dim, hidden_dim, tagset_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "MODEL_PATH = \"best_seq2seq_model.pth\"\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "def train_model(model, train_loader, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        with tqdm(total=len(train_loader), desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"batch\") as pbar:\n",
    "            for sequences, labels, mask in train_loader:\n",
    "                sequences, labels, mask = sequences.to(device), labels.to(device), mask.to(device)\n",
    "                # mask = (labels != -1).float()  # Mask padded labels\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss = model(sequences, tags=labels, mask=mask)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                pbar.update(1)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "        torch.save(model.state_dict(),MODEL_PATH)\n",
    "\n",
    "train_model(model, train_loader, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[0, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 0, 1, 1, 1], [0, 0, 1, 1, 0], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 0, 1, 1, 0], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 0, 1], [0, 1, 1, 1, 0, 1], [0, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1, 0, 1, 0, 1, 1, 1], [0, 1, 1, 1, 0, 1], [0, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1]]\n",
      "Predictions: [[0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 0, 1, 1, 0, 1], [0, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 0, 1], [1, 0, 1, 1, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1, 0, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 0, 1, 1, 0], [0, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1], [0, 1, 1, 1, 1, 0, 1, 1], [0, 1, 0, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 0, 1, 1], [0, 1, 1, 1, 1, 1, 1, 0, 1, 1], [0, 1, 1, 1, 0, 1, 0, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1], [0, 1, 0, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 0, 1, 1, 1, 1], [0, 1, 0, 1], [0, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1], [0, 1, 0, 1, 1]]\n",
      "Predictions: [[0, 1, 1, 1, 0, 1], [0, 1, 1, 1], [0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0], [0, 1, 1, 1, 0, 1, 1, 1], [0, 1, 1, 1, 1, 0], [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1], [0, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1], [0, 1, 1, 1, 0, 1], [0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1], [0, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1], [0, 1, 1], [0, 1, 1, 0], [0, 1, 1]]\n",
      "Predictions: [[1, 0, 1, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1], [0, 1, 1, 1, 0, 1, 1, 0, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 0], [0, 1, 1, 1, 1], [0, 0, 1, 1, 0, 1, 1], [0, 1, 1, 1, 1, 0, 1, 1, 1], [0, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1, 1, 1], [0, 1, 1, 1, 1], [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1], [0, 1, 1, 1, 0, 1, 1, 1], [0, 1, 1, 0, 1]]\n",
      "Dev Set Accuracy: 82.22%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels, mask in data_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            \n",
    "            # Mask for valid positions (non-padded)\n",
    "            # mask = (labels != -1).float()\n",
    "\n",
    "            # Get predictions from the model\n",
    "            predicted_indices = model(sequences, mask=mask)\n",
    "\n",
    "            # Collect predictions and targets\n",
    "            for pred_seq, true_seq, seq_mask in zip(predicted_indices, labels, mask):\n",
    "                # Convert mask to int for slicing\n",
    "                seq_len = int(seq_mask.sum().item())\n",
    "                \n",
    "                # Remove padding and collect valid predictions and targets\n",
    "                all_predictions.extend(pred_seq[:seq_len])\n",
    "                all_targets.extend(true_seq[:seq_len].tolist())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    return accuracy\n",
    "\n",
    "# Prediction Loop\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for sequences, _, mask in val_loader:\n",
    "        sequences = sequences.to(device)\n",
    "        predictions = model(sequences, mask=mask)\n",
    "        print(\"Predictions:\", predictions)\n",
    "\n",
    "\n",
    "# Evaluate the model on the dev dataset\n",
    "accuracy = evaluate_model(model, val_loader, device)\n",
    "print(f\"Dev Set Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences, char_to_idx):\n",
    "        self.sequences = [[char_to_idx.get(char, char_to_idx['<UNK>']) for char in seq] for seq in sequences]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        return torch.tensor(sequence, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_unlabeled(batch):\n",
    "    if not batch:\n",
    "        raise ValueError(\"Received an empty batch.\")\n",
    "\n",
    "    # Ensure all items are valid 1-dimensional tensors\n",
    "    valid_sequences = [seq for seq in batch if len(seq.shape) == 1]\n",
    "    if not valid_sequences:\n",
    "        raise ValueError(\"All sequences in the batch are invalid or empty.\")\n",
    "\n",
    "    max_len = max(len(seq) for seq in valid_sequences)\n",
    "\n",
    "    # Pad sequences to the maximum length\n",
    "    padded_sequences = [\n",
    "        torch.cat([seq, torch.zeros(max_len - len(seq), dtype=torch.long)], dim=0)\n",
    "        for seq in valid_sequences\n",
    "    ]\n",
    "\n",
    "    return torch.stack(padded_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_unlabeled(model, data_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations\n",
    "        for sequences, mask in data_loader:\n",
    "            sequences, mask = sequences.to(device), mask.to(device)\n",
    "            # Get the most likely tag sequence using the CRF decoder\n",
    "            pred_tags = model(sequences, mask=mask)\n",
    "            predictions.extend(pred_tags)\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 4/4 [00:00<00:00, 25.54it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = TestDataset(test_words, char_to_idx)\n",
    "# print(test_dataset[40])\n",
    "# print(char_to_idx)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn_unlabeled)\n",
    "\n",
    "model = BiLSTMCRF(vocab_size, embedding_dim, hidden_dim, tagset_size)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# print(vocab_size)\n",
    "# for seq in test_loader:\n",
    "#     print(seq)\n",
    "#     print(torch.max(seq))\n",
    "results = []\n",
    "with torch.no_grad():\n",
    "    for sequences in tqdm(test_loader, desc=\"Running Inference\"):\n",
    "        sequences = sequences.to(device)\n",
    "        mask = (sequences != 0).float()  # Mask for non-padded positions\n",
    "        predictions = model(sequences, mask=mask)\n",
    "        results.extend(predictions)\n",
    "\n",
    "def decode_tag(words, tags):\n",
    "    decoded = []\n",
    "    for word, tag in zip(words, tags):\n",
    "        decoded_word = []\n",
    "        for idx, (w, t) in enumerate(zip(word, tag)):\n",
    "            if t == 0 and idx != 0:\n",
    "                decoded_word.append(' ')\n",
    "            decoded_word.append(w)\n",
    "        decoded.append(''.join(decoded_word))\n",
    "    return decoded\n",
    "\n",
    "decoded = decode_tag(test_words, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the decoded words to a file with name pred_tar.test.tgt\n",
    "with open('pred_shp.test.tgt', 'w') as file:\n",
    "    for word in decoded:\n",
    "        file.write(word + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
